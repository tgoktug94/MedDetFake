{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOgULC8idPlN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "zip_path   = \"/content/Medical Image Classification.zip\"\n",
        "extract_to = \"/content/medical_cls\"\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "    zf.extractall(extract_to)\n",
        "\n",
        "!ls -R \"{extract_to}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 classes model"
      ],
      "metadata": {
        "id": "n9m4H5C7qKAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, random\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "IMG_SIZE   = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(10),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "root = \"/content/medical_cls\"   # zip'i buraya a√ßmƒ±≈ütƒ±k\n",
        "organs = [\"brain\", \"chest\", \"kidney\", \"lung\"]\n",
        "subtypes = [\"real\", \"fake\"]\n",
        "\n",
        "class_names = [\n",
        "    \"brain_real\", \"brain_fake\",\n",
        "    \"chest_real\", \"chest_fake\",\n",
        "    \"kidney_real\", \"kidney_fake\",\n",
        "    \"lung_real\", \"lung_fake\"\n",
        "]\n",
        "print(\"Sƒ±nƒ±flar:\", class_names)\n",
        "num_classes = len(class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN_guIPWqL82",
        "outputId": "f87e307b-931b-495f-a9b5-26339dfbfa56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n",
            "Sƒ±nƒ±flar: ['brain_real', 'brain_fake', 'chest_real', 'chest_fake', 'kidney_real', 'kidney_fake', 'lung_real', 'lung_fake']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_samples_8 = []   # (img_path, class_idx)\n",
        "\n",
        "for organ_idx, organ in enumerate(organs):\n",
        "    for subtype_idx, subtype in enumerate(subtypes):\n",
        "        cls_name = f\"{organ}_{subtype}\"\n",
        "        cls_idx  = class_names.index(cls_name)\n",
        "\n",
        "        img_dir = os.path.join(root, organ, subtype)\n",
        "        paths = []\n",
        "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
        "            paths.extend(glob.glob(os.path.join(img_dir, ext)))\n",
        "        paths = sorted(paths)\n",
        "\n",
        "        print(f\"{cls_name} -> {len(paths)} images\")\n",
        "\n",
        "        for p in paths:\n",
        "            all_samples_8.append((p, cls_idx))\n",
        "\n",
        "print(\"Total sample count (8 sƒ±nƒ±f):\", len(all_samples_8))\n",
        "print(\"Example:\", all_samples_8[0] if all_samples_8 else \"Not\")\n"
      ],
      "metadata": {
        "id": "l6bK-76IotKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [p for (p, c) in all_samples_8]\n",
        "labels = [c for (p, c) in all_samples_8]\n",
        "\n",
        "# √∂nce train + temp\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    paths, labels, test_size=0.3, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# temp'i val + test olarak b√∂l\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_paths))\n",
        "print(\"Val  :\", len(val_paths))\n",
        "print(\"Test :\", len(test_paths))\n"
      ],
      "metadata": {
        "id": "fS17B_b5qQQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Medical8ClassDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.paths[idx]\n",
        "        label    = self.labels[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "train_set_8 = Medical8ClassDataset(train_paths, train_labels, train_transform)\n",
        "val_set_8   = Medical8ClassDataset(val_paths,   val_labels,   test_transform)\n",
        "test_set_8  = Medical8ClassDataset(test_paths,  test_labels,  test_transform)\n",
        "\n",
        "train_loader_8 = DataLoader(train_set_8, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
        "val_loader_8   = DataLoader(val_set_8,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader_8  = DataLoader(test_set_8,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Train batches:\", len(train_loader_8))\n",
        "print(\"Val   batches:\", len(val_loader_8))\n",
        "print(\"Test  batches:\", len(test_loader_8))\n"
      ],
      "metadata": {
        "id": "roHR-c8GqTDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet8 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Son katmanƒ± 8 sƒ±nƒ±fa uyarlayalƒ±m\n",
        "in_features = resnet8.fc.in_features\n",
        "resnet8.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "resnet8 = resnet8.to(DEVICE)\n",
        "\n",
        "criterion_8 = nn.CrossEntropyLoss()\n",
        "optimizer_8 = torch.optim.Adam(resnet8.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "rEetOQQEqT2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch_8(model, loader, optimizer=None):\n",
        "    if optimizer is None:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for imgs, labels in loader:\n",
        "        imgs   = imgs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion_8(outputs, labels)\n",
        "\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "        total_samples += imgs.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    avg_acc  = total_correct / total_samples\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "EPOCHS_8 = 15\n",
        "best_val_acc_8 = 0.0\n",
        "best_path_8 = \"/content/resnet_8class_best.pth\"\n",
        "\n",
        "for epoch in range(1, EPOCHS_8+1):\n",
        "    train_loss, train_acc = run_epoch_8(resnet8, train_loader_8, optimizer=optimizer_8)\n",
        "    val_loss,   val_acc   = run_epoch_8(resnet8, val_loader_8,   optimizer=None)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS_8} | \"\n",
        "          f\"TrainLoss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "          f\"ValLoss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc_8:\n",
        "        best_val_acc_8 = val_acc\n",
        "        torch.save(resnet8.state_dict(), best_path_8)\n",
        "        print(\"  -> Yeni en iyi model kaydedildi:\", best_path_8)\n",
        "\n",
        "print(\"En iyi val acc (8 sƒ±nƒ±f):\", best_val_acc_8)\n"
      ],
      "metadata": {
        "id": "BQIYmsdqqVkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En iyi modeli y√ºkle\n",
        "resnet8.load_state_dict(torch.load(best_path_8, map_location=DEVICE))\n",
        "\n",
        "test_loss_8, test_acc_8 = run_epoch_8(resnet8, test_loader_8, optimizer=None)\n",
        "print(f\"8-CLASS TEST | Loss: {test_loss_8:.4f}  Acc: {test_acc_8:.4f}\")\n"
      ],
      "metadata": {
        "id": "KwnQrYq-qY5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "resnet8.eval()\n",
        "all_labels = []\n",
        "all_preds  = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader_8:\n",
        "        imgs   = imgs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        outputs = resnet8(imgs)\n",
        "        preds   = outputs.argmax(dim=1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds  = np.array(all_preds)\n",
        "\n",
        "print(\"\\nüîç CLASSIFICATION REPORT (8 sƒ±nƒ±f, test seti)\\n\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(8,7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - 8-Class Test\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o1haclkcqavR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}